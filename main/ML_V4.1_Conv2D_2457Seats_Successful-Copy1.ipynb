{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#This cell is created to convert GH raw point info into class objects with adjancency status\n",
    "#Originally written in Spyder, do not run this cell unless necessary\n",
    "\n",
    "\"\"\"\n",
    "Created on Thu Feb 25 15:18:57 2021\n",
    "\n",
    "@author: Henan.Liu\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "\n",
    "#loc = r\"D:/WFH2020/210202_IOC/RL/Spreadsheet/Raw.xlsx\"\n",
    "loc = r\"X:/henan.liu/__ML/Spreadsheet/0504_Raw.xlsx\"\n",
    "rawFile = openpyxl.load_workbook(loc)\n",
    "rawSheet = rawFile.active\n",
    "maxRow = rawSheet.max_row\n",
    "\n",
    "lst = []\n",
    "ptLst = []\n",
    "#print (rawSheet[1])\n",
    "\n",
    "for i in range(maxRow):\n",
    "    subList = []\n",
    "    for cell in rawSheet[i+1]:\n",
    "        cell = cell.value\n",
    "        if cell:\n",
    "            cell = cell[1:-1].split(\",\")\n",
    "            cell = cell[:-1]\n",
    "            subList.append([float(stuff) for stuff in cell])\n",
    "    lst.append(subList)\n",
    "\n",
    "class point():\n",
    "    def __init__(self,row,num,pos,length):\n",
    "        self.pos = pos\n",
    "        self.row = row\n",
    "        self.num = num\n",
    "        self.length = length\n",
    "        self.neighbor = []\n",
    "        \n",
    "    def assign(self, indexN):\n",
    "        self.neighbor.append(indexN)\n",
    "        \n",
    "final_List = []\n",
    "parallel_List = []\n",
    "for i,row in enumerate(lst):\n",
    "    subList = []\n",
    "    for j,pt in enumerate(row):\n",
    "        obj = point(i,j,np.asarray(pt),len(row))\n",
    "        ptLst.append(obj.pos)\n",
    "        subList.append(obj)\n",
    "        parallel_List.append(obj)\n",
    "    final_List.append(subList)\n",
    "ptArray = np.asarray(ptLst)\n",
    "\n",
    "for i, row in enumerate(final_List):\n",
    "    print (i)\n",
    "    for j, pt in enumerate(row):\n",
    "        point_tree = spatial.cKDTree(ptArray)\n",
    "        point_index = point_tree.query_ball_point(pt.pos, 1000)\n",
    "        for index in point_index:\n",
    "            \n",
    "            pt.assign([parallel_List[index].row,parallel_List[index].num])\n",
    "              \n",
    "\n",
    "#Writing worksheet\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active\n",
    "for i, row in enumerate(final_List):\n",
    "    for j, pt in enumerate(row):     \n",
    "        \n",
    "        ws.cell(row = i+1, column = j+1).value= str([pt.row, pt.num, pt.pos.tolist(), pt.length, pt.neighbor])\n",
    "newloc = r\"X:/henan.liu/__ML/Spreadsheet/0504_Product.xlsx\"\n",
    "wb.save(newloc)\n",
    "#dist = np.linalg.norm(ptArray[1] - ptArray[2])\n",
    "#print (ptArray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import ast\n",
    "import math\n",
    "\n",
    "#Read spreadsheet\n",
    "loc = r\"X:/henan.liu/__ML/Spreadsheet/0504_Product.xlsx\"\n",
    "wb = openpyxl.load_workbook(loc)\n",
    "ws = wb.active\n",
    "lstManual = [4,3,2,1]\n",
    "\n",
    "#Initialize objects\n",
    "class seat():\n",
    "    def __init__(self,row,num,pos,length,indexN,NO):\n",
    "        self.pos = pos\n",
    "        self.state = 0\n",
    "        self.row = row\n",
    "        self.num = num\n",
    "        self.length = length\n",
    "        self.indexN = indexN\n",
    "        self.NO = NO\n",
    "        \n",
    "    def assign(self, state):\n",
    "        self.state = state\n",
    "        \n",
    "    def refresh(self):\n",
    "        self.state = 0\n",
    "        \n",
    "lstSeat = []\n",
    "Flat_lstSeat = []\n",
    "\n",
    "NO = 0\n",
    "for i,row in enumerate(ws):\n",
    "    rowTemp = []\n",
    "    for j, num in enumerate(row):\n",
    "        if num.value:\n",
    "            value_list = ast.literal_eval(num.value)\n",
    "            pos = value_list[2]\n",
    "            length = value_list[3]\n",
    "            indexN = value_list[4]\n",
    "            obj = seat(i,j,pos,length,indexN,NO)\n",
    "            rowTemp.append(obj)\n",
    "            Flat_lstSeat.append(obj)\n",
    "            NO += 1\n",
    "\n",
    "    lstSeat.append(rowTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Environment\n",
    "class environment():\n",
    "    def __init__(self,lstManual,lstSeat,Flat_lstSeat):\n",
    "        self.row = 0\n",
    "        self.num = 0\n",
    "        self.lstManual = lstManual\n",
    "        self.lstSeat = lstSeat\n",
    "        self.done = False        \n",
    "        self.map = np.zeros([len(lstSeat),len(max(lstSeat,key = lambda x: len(x))),1])\n",
    "        #self.map = np.zeros(len(Flat_lstSeat))\n",
    "        #self.map = np.reshape(self.map, (-1,1))\n",
    "        self.count_total = 0\n",
    "        self.OBSERVATION_SPACE_VALUES = (self.map.shape)\n",
    "        self.ACTION_SPACE_SIZE = 5\n",
    "        self.total = sum(len(sub) for sub in lstSeat)\n",
    "        self.reward = 0\n",
    "        self.detect_legal()\n",
    "        self.occupied = 0\n",
    "        \n",
    "    def detect_legal(self):\n",
    "        clear = 1\n",
    "        for i,pLine in enumerate(self.lstSeat[self.row:],start =self.row):\n",
    "            for j, pt in enumerate(pLine):\n",
    "                for k, opt in enumerate(self.lstManual):\n",
    "                    if j + opt <= len(pLine):\n",
    "                        clear = 0\n",
    "                        for u in range(opt):\n",
    "                            if pLine[j + u].state!=0:\n",
    "                                clear += 1\n",
    "                    if clear == 0:\n",
    "                        self.max_opt = opt\n",
    "                        self.row = i\n",
    "                        self.num = j\n",
    "                        break\n",
    "                if clear ==0:\n",
    "                    break\n",
    "            if clear ==0:\n",
    "                break\n",
    "        if clear != 0:\n",
    "            self.done = True\n",
    "\n",
    "    def move(self,action):\n",
    "        self.detect_legal()\n",
    "        if action>self.max_opt:\n",
    "            print (\"Environemnt Warning: illegal move, too big an action\")\n",
    "            \n",
    "        elif action == 0:\n",
    "            self.lstSeat[self.row][self.num].assign(0.2)\n",
    "            self.map[self.row][self.num][0] = 0.1\n",
    "            #index =  self.lstSeat[self.row][self.num].NO\n",
    "            #self.map[index][0] = 0.2\n",
    "            self.occupied += 1\n",
    "            self.reward = 0\n",
    "            \n",
    "        else:\n",
    "            self.count_total += action\n",
    "            self.occupied += action\n",
    "            self.reward = action/4\n",
    "            for u in range(action):\n",
    "                self.lstSeat[self.row][self.num + u].assign(action)\n",
    "                index =  self.lstSeat[self.row][self.num + u].NO\n",
    "                #self.map[index][0] = action\n",
    "                self.map[self.row][self.num + u][0] = action #Used to be = action\n",
    "                \n",
    "            for u in range(action):\n",
    "                index_list = self.lstSeat[self.row][self.num + u].indexN\n",
    "                for index in index_list:\n",
    "                    if self.lstSeat[index[0]][index[1]].state == 0:\n",
    "                        self.lstSeat[index[0]][index[1]].assign(0.1)\n",
    "                        self.map[index[0]][index[1]][0] = 0.1\n",
    "                        #mapIndex = self.lstSeat[index[0]][index[1]].NO\n",
    "                        #self.map[mapIndex][0] = 0.1\n",
    "                        self.occupied += 1\n",
    "                        #self.reward -= 1\n",
    "        self.detect_legal()\n",
    "        #self.reward = self.count_total / self.occupied\n",
    "        #if env.done:\n",
    "            #self.reward = self.count_total - 90\n",
    "            \n",
    "    def check(self):\n",
    "        obs_list = []\n",
    "        for pLine in self.lstSeat:\n",
    "            for pt in pLine:\n",
    "                obs_list.append(pt.state) \n",
    "        return np.array(obs_list)\n",
    "\n",
    "    def reset(self):\n",
    "        for thing in self.lstSeat:\n",
    "            for stuff in thing:\n",
    "                stuff.refresh()\n",
    "                \n",
    "        self.done = False\n",
    "        #self.map[:] = 0\n",
    "        self.map = np.zeros([len(lstSeat),len(max(lstSeat,key = lambda x: len(x))),1])\n",
    "        self.count_total = 0\n",
    "        self.row = 0\n",
    "        self.num = 0\n",
    "        self.reward = 0\n",
    "        self.occupied = 0\n",
    "        self.detect_legal()\n",
    "        #return self.map\n",
    "        \n",
    "env = environment(lstManual, lstSeat, Flat_lstSeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n",
      "(216, 13, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c4a5ca9d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 15552x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "env.reset()\n",
    "test01 = env.map\n",
    "while not env.done:\n",
    "    action = env.max_opt\n",
    "    #print (\"A\",env.max_opt)\n",
    "    #print (action)\n",
    "    env.move(action)\n",
    "    #print (\"B\",env.max_opt)\n",
    "    #print (env.reward)\n",
    "#print (env.map/4)\n",
    "#env.reset()\n",
    "print (env.count_total)\n",
    "print (env.OBSERVATION_SPACE_VALUES)\n",
    "#print (env.map)\n",
    "img = env.map/4\n",
    "img = np.reshape(img, (216, 13))\n",
    "#res = cv2.resize(img, dsize=(60,60), interpolation=cv2.INTER_CUBIC)\n",
    "plt.figure(figsize = (216,20))\n",
    "plt.imshow(img,cmap=plt.cm.binary)\n",
    "#plt.show()\n",
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend.tensorflow_backend as backend\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "REPLAY_MEMORY_SIZE = 100000\n",
    "MIN_REPLAY_MEMORY_SIZE = 5000\n",
    "MODEL_NAME = \"Seating_Layout\"\n",
    "MINIBATCH_SIZE = 32\n",
    "DISCOUNT = 1\n",
    "UPDATE_TARGET_EVERY= 10\n",
    "EPISODES = 10000\n",
    "PLOT_EVERY = 50\n",
    "\n",
    "# Exploration settings\n",
    "epsilon = 0.9  \n",
    "EPSILON_DECAY = epsilon/(EPISODES//3)\n",
    "MIN_EPSILON = 0.1\n",
    "\n",
    "#Plotting\n",
    "plotting = [[],[],[]]\n",
    "\n",
    "# Agent class\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "\n",
    "        # Main model\n",
    "        self.model = self.create_model()\n",
    "        \n",
    "        #Load Model\n",
    "        #self.model.load_weights('X:/henan.liu/__ML/Weights/Model_V4_0_154_C')\n",
    "        #self.model = keras.models.load_model('D:/WFH2020/210202_IOC/RL/TrainingModel/Model_V3_7_G')\n",
    "        #self.target_model = keras.models.load_model('D:/WFH2020/210202_IOC/RL/TrainingModel/Model_V3_7_G')\n",
    "        \n",
    "        # Target network\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        # An array with last n steps for training\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        \n",
    "        #Load Memory\n",
    "        #self.replay_memory = pickle.load( open( 'X:/henan.liu/__ML/Pickle/Model_V4_0_154_B', 'rb' ) )\n",
    "        \n",
    "        # Used to count when to update target network with main network's weights\n",
    "        self.target_update_counter = 0\n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        #model.add(Conv1D(32, 26, strides = 2, activation = 'relu', input_shape=env.OBSERVATION_SPACE_VALUES)) \n",
    "        \n",
    "        #model.add(Conv1D(64, 12, strides = 1, activation = 'relu'))\n",
    "        \n",
    "        #model.add(Conv1D(64, 3, strides = 1, activation = 'relu'))\n",
    "        \n",
    "        #model.add(Flatten())\n",
    "        \n",
    "        #model.add(Dense(512,activation = \"relu\"))\n",
    "        \n",
    "        #model.add(Dense(env.ACTION_SPACE_SIZE, activation='linear'))\n",
    "\n",
    "        model.add(Conv2D(16, 4, strides = 2,padding = 'same', input_shape=env.OBSERVATION_SPACE_VALUES, data_format='channels_last')) \n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(32, 3, strides = 1,padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        #model.add(Conv2D(64, 3, strides = 1,padding = 'same'))\n",
    "        #model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Flatten()) \n",
    "        model.add(Dense(256,activation = \"relu\"))\n",
    "\n",
    "        model.add(Dense(env.ACTION_SPACE_SIZE, activation='linear')) \n",
    "        \n",
    "        model.compile(loss=keras.losses.Huber(), optimizer=Adam(lr=0.00025))\n",
    "        return model\n",
    "\n",
    "    # Adds step's data to a memory replay array\n",
    "    # (observation space, action, reward, new observation space, done)\n",
    "    def update_replay_memory(self, transition):\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    # Trains main network every step during episode\n",
    "    def train(self, terminal_state):\n",
    "                \n",
    "        # Start training only if certain number of samples is already saved\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "        \n",
    "        # Get a minibatch of random samples from memory replay table\n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "\n",
    "        # Get current states from minibatch, then query NN model for Q values\n",
    "        current_states = np.array([transition[0] for transition in minibatch])/4\n",
    "        current_qs_list = self.model.predict(current_states)\n",
    "\n",
    "        # Get future states from minibatch, then query NN model for Q values\n",
    "        # When using target network, query it, otherwise main network should be queried\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])/4\n",
    "        future_qs_list = self.target_model.predict(new_current_states)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        # Now we need to enumerate our batches\n",
    "        for index, (current_state, action, reward, new_current_state, done, step,episode,new_opt) in enumerate(minibatch):\n",
    "\n",
    "            # If not a terminal state, get new q from future states, otherwise set it to 0\n",
    "            # almost like with Q Learning, but we use just part of equation here\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index][:new_opt])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "                \n",
    "            # Update Q value for given state\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            # And append to our training data\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "        \n",
    "        # Fit on all samples as one batch, log only on terminal state\n",
    "        if terminal_state:\n",
    "            self.model.fit(np.array(X)/4, np.array(y), batch_size=MINIBATCH_SIZE, verbose=2, shuffle=False)\n",
    "        else:\n",
    "            self.model.fit(np.array(X)/4, np.array(y), batch_size=MINIBATCH_SIZE, verbose=0, shuffle=False)\n",
    "        \n",
    "        # Update target network counter every episode\n",
    "        if terminal_state:\n",
    "            self.target_update_counter += 1\n",
    "            print (\"future qs list[0] = \",future_qs_list[0], \"Step = \", minibatch[0][5],\"Episode = \", minibatch[0][6] )\n",
    "            print (\"future qs list[1] = \",future_qs_list[1], \"Step = \", minibatch[1][5],\"Episode = \", minibatch[1][6] )\n",
    "            #print (\"future qs list[2] = \",future_qs_list[2], \"Step = \", minibatch[2][5],\"Episode = \", minibatch[2][6] )\n",
    "            #print (\"future qs list[3] = \",future_qs_list[3], \"Step = \", minibatch[3][5],\"Episode = \", minibatch[3][6] )\n",
    "            \n",
    "        # If counter reaches set value, update target network with weights of main network\n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "            print (\"Target Model is updated\")\n",
    "\n",
    "    # Queries main network for Q values given current observation space (environment state)\n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(state.reshape(-1, *state.shape)/4)[0]\n",
    "        \n",
    "agent = DQNAgent()\n",
    "\n",
    "move_LIST = []\n",
    "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
    "    \n",
    "    episode_reward = 0\n",
    "    step = 0\n",
    "    env.reset()\n",
    "    current_state = np.copy(env.map)\n",
    "    move_list = []\n",
    "    while not env.done:\n",
    "        \n",
    "        opt = env.max_opt+1\n",
    "        if np.random.random()> epsilon:\n",
    "            \n",
    "            action = np.argmax(agent.get_qs(current_state)[:opt])\n",
    "            \n",
    "        else:\n",
    "            action = np.random.randint(0, opt)\n",
    "        \n",
    "        move_list.append(action)\n",
    "        env.move(action)\n",
    "        new_state = np.copy(env.map)\n",
    "        reward = env.reward\n",
    "        done = env.done\n",
    "        new_opt = env.max_opt + 1\n",
    "        episode_reward += reward\n",
    "        \n",
    "        if env.done:\n",
    "            print (episode_reward,  env.count_total,  epsilon)\n",
    "            \n",
    "            #if env.count_total>= 1060:\n",
    "               # move_LIST.append(move_list)\n",
    "        #if env.count_total > 400:\n",
    "            #agent.model.save_weights('D:/WFH2020/210202_IOC/RL/TrainingModel/Model_V3_7_H')\n",
    "            #print (\"A very cool model is saved\")\n",
    "            \n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done, step, episode, new_opt))\n",
    "        agent.train(done)\n",
    "        \n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "          \n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon -= EPSILON_DECAY\n",
    "    \n",
    "    plotting[0].append(episode)\n",
    "    plotting[1].append(env.count_total)\n",
    "    plotting[2].append(episode_reward)\n",
    "    \n",
    "    if episode % PLOT_EVERY == 0:\n",
    "        xpoints = np.array(plotting[0])\n",
    "        ypoints = np.array(plotting[1])\n",
    "        xpoints = np.mean(xpoints.reshape(-1, 5), axis=1)\n",
    "        ypoints = np.mean(ypoints.reshape(-1, 5), axis=1)\n",
    "        plt.plot(xpoints, ypoints)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save_weights('X:/henan.liu/__ML/Weights/Model_V4_1_2457_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "outfile = open('X:/henan.liu/__ML/Pickle/Model_V4_1_2457_A','wb')\n",
    "pickle.dump(agent.replay_memory,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.deque'>\n"
     ]
    }
   ],
   "source": [
    "memory = pickle.load( open( 'X:/henan.liu/__ML/Pickle/Model_V4_0_154_B', 'rb' ) )\n",
    "print (type(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 60, 61, 61, 60, 60, 66, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60]\n",
      "[0, 0, 0, 4, 0, 0, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lstSum = [sum(stuff) for stuff in lst]\n",
    "print (lstSum)\n",
    "print (lst[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "step = 0\n",
    "while not env.done:\n",
    "    \n",
    "    action = lst[6][step]\n",
    "    env.move(action)\n",
    "    step+= 1\n",
    "print (env.count_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "\n",
    "newloc = r\"X:/henan.liu/__ML/Spreadsheet/0506_Machine.xlsx\"\n",
    "newloc2 = r\"X:/henan.liu/__ML/Spreadsheet/0506_Dummy.xlsx\"\n",
    "newloc3 = r\"X:/henan.liu/__ML/Spreadsheet/0506_Machine_FullBase.xlsx\"\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "for i,stuff in enumerate(Flat_lstSeat):\n",
    "    #print (Flat_lstSeat[i].pos)\n",
    "    ws.cell(row = i+1, column = 1).value = Flat_lstSeat[i].pos[0]\n",
    "    ws.cell(row = i+1, column = 2).value = Flat_lstSeat[i].pos[1]\n",
    "    ws.cell(row = i+1, column = 4).value = Flat_lstSeat[i].state\n",
    "wb.save(newloc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for thing in agent.replay_memory:\n",
    "    if thing[2]!=0:\n",
    "        count += 1\n",
    "print (count)\n",
    "print (len(agent.replay_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (np.sum(agent.replay_memory[1][0]))\n",
    "state1 =  (agent.replay_memory[2][0])\n",
    "state2 =  (agent.replay_memory[5000][0])\n",
    "print (np.sum(agent.replay_memory[2][0]))\n",
    "print (np.sum(agent.replay_memory[5000][0]))\n",
    "a = agent.model.predict(state1.reshape(-1, *state1.shape)/4)[0]\n",
    "b = agent.model.predict(state2.reshape(-1, *state2.shape)/4)[0]\n",
    "print (a)\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[275.14117 275.12225 275.10233 275.2752  275.48358]\n",
      "275.48358 step =  0\n",
      "4 4\n",
      "[274.1834  274.23676 274.4075  274.5864  274.74646]\n",
      "274.74646 step =  1\n",
      "4 4\n",
      "[273.209   273.22723 273.26477 273.42865 273.61792]\n",
      "273.61792 step =  2\n",
      "4 4\n",
      "[272.2533  272.13324 272.21362 272.40848 272.60825]\n",
      "272.60825 step =  3\n",
      "4 4\n",
      "[271.5743  271.38144 271.29788 271.48172 271.77902]\n",
      "271.77902 step =  4\n",
      "4 4\n",
      "[270.32202 270.15607 270.45578 270.71555 270.8125 ]\n",
      "270.71555 step =  5\n",
      "3 3\n",
      "[269.65067 269.3585  269.41135 269.58566 269.78406]\n",
      "269.78406 step =  6\n",
      "4 4\n",
      "[268.78265 268.56134 268.5385  268.67407 268.92957]\n",
      "268.92957 step =  7\n",
      "4 4\n",
      "[267.60428 267.55426 267.81143 268.05872 268.1461 ]\n",
      "268.05872 step =  8\n",
      "3 3\n",
      "[266.93796 266.86594 266.93    267.09003 267.27872]\n",
      "267.27872 step =  9\n",
      "4 4\n",
      "[266.2045  265.8321  265.928   266.11337 266.33783]\n",
      "266.33783 step =  10\n",
      "4 4\n",
      "[264.8597  264.7811  265.07898 265.25223 265.39786]\n",
      "265.25223 step =  11\n",
      "3 3\n",
      "[264.20248 263.94513 264.02567 264.21356 264.40555]\n",
      "264.40555 step =  12\n",
      "4 4\n",
      "[263.33347 263.1424  263.22455 263.32336 263.46494]\n",
      "263.46494 step =  13\n",
      "4 4\n",
      "[262.21042 262.15924 262.35422 262.5211  262.64258]\n",
      "262.5211 step =  14\n",
      "3 3\n",
      "[261.2864  261.30258 261.2942  261.3769  261.57922]\n",
      "261.57922 step =  15\n",
      "4 4\n",
      "[260.13962 260.26645 260.2824  260.29187 260.40527]\n",
      "260.40527 step =  16\n",
      "4 4\n",
      "[259.21872 259.15338 259.11588 259.22693 259.35513]\n",
      "259.35513 step =  17\n",
      "4 4\n",
      "[258.0733  258.09085 258.04346 258.07178 258.2288 ]\n",
      "258.2288 step =  18\n",
      "4 4\n",
      "[257.07043 256.90637 256.878   257.00375 257.16638]\n",
      "257.16638 step =  19\n",
      "4 4\n",
      "[255.9556  255.99991 256.0285  256.13644 256.22592]\n",
      "256.22592 step =  20\n",
      "4 4\n",
      "[255.06902 255.07632 255.04558 255.19734 255.34735]\n",
      "255.34735 step =  21\n",
      "4 4\n",
      "[254.13757 254.12973 254.06299 254.1521  254.40073]\n",
      "254.40073 step =  22\n",
      "4 4\n",
      "[253.54556 253.0755  253.16866 253.10193 253.01877]\n",
      "253.54556 step =  23\n",
      "4 0\n",
      "[253.45596 252.9708  253.04279 252.93454 252.8774 ]\n",
      "253.45596 step =  24\n",
      "4 0\n",
      "[253.48994 253.09315 253.091   253.10559 253.24913]\n",
      "253.48994 step =  25\n",
      "4 0\n",
      "[253.36746 253.19365 253.1709  253.33202 253.5596 ]\n",
      "253.5596 step =  26\n",
      "4 4\n",
      "[252.28114 252.23131 252.44931 252.60759 252.57854]\n",
      "252.60759 step =  27\n",
      "3 3\n",
      "[251.41147 251.42102 251.46646 251.61153 251.78598]\n",
      "251.78598 step =  28\n",
      "4 4\n",
      "[250.54709 250.52715 250.45892 250.6051  250.85582]\n",
      "250.85582 step =  29\n",
      "4 4\n",
      "[249.69719 249.59981 249.80598 249.97801 250.01434]\n",
      "249.97801 step =  30\n",
      "3 3\n",
      "[248.88144 248.86426 248.97028 249.1727  249.36902]\n",
      "249.36902 step =  31\n",
      "4 4\n",
      "[248.07605 248.01404 248.07188 248.222   248.4497 ]\n",
      "248.4497 step =  32\n",
      "4 4\n",
      "[247.26941 246.8553  246.89732 246.7963  246.8757 ]\n",
      "247.26941 step =  33\n",
      "4 0\n",
      "[247.27219 246.82884 246.85068 246.67502 246.75398]\n",
      "247.27219 step =  34\n",
      "4 0\n",
      "[247.29239 246.87503 246.91328 246.73714 246.86351]\n",
      "247.29239 step =  35\n",
      "4 0\n",
      "[247.2341  246.9684  247.03172 246.99857 247.25742]\n",
      "247.25742 step =  36\n",
      "4 4\n",
      "[246.24152 245.83754 245.90395 246.26057 246.27892]\n",
      "246.24152 step =  37\n",
      "2 0\n",
      "[246.21979 245.73001 245.7989  246.19756 246.21559]\n",
      "246.21979 step =  38\n",
      "1 0\n",
      "[246.01897 245.97673 246.15146 246.4171  246.4043 ]\n",
      "246.4171 step =  39\n",
      "3 3\n",
      "[245.2374  245.1565  245.1069  245.33456 245.48749]\n",
      "245.48749 step =  40\n",
      "4 4\n",
      "[244.24712 244.07747 244.12439 244.25293 244.4257 ]\n",
      "244.4257 step =  41\n",
      "4 4\n",
      "[243.10521 242.86386 243.13318 243.3105  243.33466]\n",
      "243.3105 step =  42\n",
      "3 3\n",
      "[242.32501 242.18307 242.09273 242.21185 242.3763 ]\n",
      "242.3763 step =  43\n",
      "4 4\n",
      "[241.26665 241.02045 241.11111 241.2129  241.3661 ]\n",
      "241.3661 step =  44\n",
      "4 4\n",
      "[239.96184 239.75467 240.07027 240.23463 240.33093]\n",
      "240.23463 step =  45\n",
      "3 3\n",
      "[239.11298 238.93796 239.03857 239.12877 239.28253]\n",
      "239.28253 step =  46\n",
      "4 4\n",
      "[238.20673 237.96623 238.06512 238.22478 238.34738]\n",
      "238.34738 step =  47\n",
      "4 4\n",
      "[237.1284  236.99326 237.26646 237.44708 237.55064]\n",
      "237.44708 step =  48\n",
      "3 3\n",
      "[236.43156 236.3393  236.3944  236.57976 236.76675]\n",
      "236.76675 step =  49\n",
      "4 4\n",
      "[235.64273 235.36768 235.56984 235.71446 235.8602 ]\n",
      "235.8602 step =  50\n",
      "4 4\n",
      "[234.41884 234.38477 234.62259 234.83661 234.913  ]\n",
      "234.83661 step =  51\n",
      "3 3\n",
      "[233.70963 233.54619 233.59172 233.79352 233.98007]\n",
      "233.98007 step =  52\n",
      "4 4\n",
      "[232.93857 232.69632 232.77109 232.9298  233.06955]\n",
      "233.06955 step =  53\n",
      "4 4\n",
      "[231.79234 231.65079 231.93794 232.13318 232.29396]\n",
      "232.13318 step =  54\n",
      "3 3\n",
      "[231.1098  230.96805 231.09229 231.2602  231.47855]\n",
      "231.47855 step =  55\n",
      "4 4\n",
      "[230.29932 230.21526 230.28821 230.53232 230.72961]\n",
      "230.72961 step =  56\n",
      "4 4\n",
      "[229.2473  229.34239 229.3559  229.66766 229.82062]\n",
      "229.82062 step =  57\n",
      "4 4\n",
      "[228.48492 228.3896  228.55801 228.81862 228.95885]\n",
      "228.95885 step =  58\n",
      "4 4\n",
      "[227.51036 227.6792  227.89983 228.20583 228.29333]\n",
      "228.29333 step =  59\n",
      "4 4\n",
      "[226.84677 226.68936 227.00385 227.3547  227.37714]\n",
      "227.3547 step =  60\n",
      "3 3\n",
      "[226.10434 226.09795 226.16777 226.43333 226.6307 ]\n",
      "226.6307 step =  61\n",
      "4 4\n",
      "[225.47316 225.33089 225.33435 225.5615  225.79488]\n",
      "225.79488 step =  62\n",
      "4 4\n",
      "[224.39406 224.24486 224.54199 224.84557 224.88293]\n",
      "224.84557 step =  63\n",
      "3 3\n",
      "[223.64429 223.47739 223.6111  223.8303  224.01712]\n",
      "224.01712 step =  64\n",
      "4 4\n",
      "[222.77074 222.47568 222.51424 222.7052  222.91356]\n",
      "222.91356 step =  65\n",
      "4 4\n",
      "[221.58621 221.51321 221.59784 221.67192 221.74117]\n",
      "221.67192 step =  66\n",
      "3 3\n",
      "[220.7381  220.66574 220.49059 220.53514 220.76389]\n",
      "220.76389 step =  67\n",
      "4 4\n",
      "[219.59625 219.52773 219.38516 219.36015 219.6098 ]\n",
      "219.6098 step =  68\n",
      "4 4\n",
      "[218.46748 218.42276 218.4667  218.52185 218.59906]\n",
      "218.52185 step =  69\n",
      "3 3\n",
      "[217.54344 217.52351 217.45743 217.49646 217.7326 ]\n",
      "217.7326 step =  70\n",
      "4 4\n",
      "[216.42331 216.36206 216.35606 216.4246  216.64796]\n",
      "216.64796 step =  71\n",
      "4 4\n",
      "[215.15166 215.19661 215.1364  215.20192 215.49184]\n",
      "215.49184 step =  72\n",
      "4 4\n",
      "[214.38449 213.94302 213.98076 213.85178 213.82224]\n",
      "214.38449 step =  73\n",
      "4 0\n",
      "[214.2665  213.84265 213.83879 213.7391  213.78214]\n",
      "214.2665 step =  74\n",
      "4 0\n",
      "[214.15773 213.77579 213.7849  213.79472 213.89986]\n",
      "214.15773 step =  75\n",
      "4 0\n",
      "[213.88008 213.75446 213.84727 214.005   214.16882]\n",
      "214.16882 step =  76\n",
      "4 4\n",
      "[212.8311  212.6838  212.9263  213.04768 213.07379]\n",
      "213.04768 step =  77\n",
      "3 3\n",
      "[211.93185 211.77176 211.78935 211.93839 212.16408]\n",
      "212.16408 step =  78\n",
      "4 4\n",
      "[210.85034 210.68541 210.71623 210.84364 211.02377]\n",
      "211.02377 step =  79\n",
      "4 4\n",
      "[209.96887 209.78963 210.02913 210.13959 210.16377]\n",
      "210.13959 step =  80\n",
      "3 3\n",
      "[209.26007 209.15839 209.20273 209.40833 209.65726]\n",
      "209.65726 step =  81\n",
      "4 4\n",
      "[208.47252 208.51294 208.62274 208.82832 209.00563]\n",
      "209.00563 step =  82\n",
      "4 4\n",
      "[207.76634 207.7173  207.74133 207.8796  208.22421]\n",
      "208.22421 step =  83\n",
      "4 4\n",
      "[207.3846  206.82637 206.86258 206.77324 206.7519 ]\n",
      "207.3846 step =  84\n",
      "4 0\n",
      "[207.28271 206.68585 206.70358 206.61275 206.66928]\n",
      "207.28271 step =  85\n",
      "4 0\n",
      "[207.18524 206.6921  206.62799 206.66383 206.9439 ]\n",
      "207.18524 step =  86\n",
      "4 0\n",
      "[206.90494 206.61407 206.6557  206.82242 207.12921]\n",
      "207.12921 step =  87\n",
      "4 4\n",
      "[205.82335 205.66591 205.90483 206.05637 206.07365]\n",
      "206.05637 step =  88\n",
      "3 3\n",
      "[204.85109 204.72357 204.78758 204.99483 205.19574]\n",
      "205.19574 step =  89\n",
      "4 4\n",
      "[203.86244 203.66808 203.71742 203.92293 204.1576 ]\n",
      "204.1576 step =  90\n",
      "4 4\n",
      "[202.9756  202.83553 203.04411 203.18779 203.22105]\n",
      "203.18779 step =  91\n",
      "3 3\n",
      "[202.11781 202.05617 202.14195 202.29672 202.50803]\n",
      "202.50803 step =  92\n",
      "4 4\n",
      "[201.16061 201.0772  201.17068 201.3066  201.53242]\n",
      "201.53242 step =  93\n",
      "4 4\n",
      "[200.4616  199.9906  200.08252 200.06718 200.06906]\n",
      "200.4616 step =  94\n",
      "4 0\n",
      "[200.5263  199.99023 200.05208 199.96793 200.01134]\n",
      "200.5263 step =  95\n",
      "4 0\n",
      "[200.63303 200.10016 200.14563 200.06741 200.15372]\n",
      "200.63303 step =  96\n",
      "4 0\n",
      "[200.52003 200.15729 200.2252  200.34752 200.57466]\n",
      "200.57466 step =  97\n",
      "4 4\n",
      "[199.48586 199.05913 199.15604 199.56001 199.61864]\n",
      "199.48586 step =  98\n",
      "2 0\n",
      "[199.51309 198.99715 199.08598 199.52354 199.59523]\n",
      "199.51309 step =  99\n",
      "1 0\n",
      "[199.26668 199.11754 199.30505 199.59741 199.62155]\n",
      "199.59741 step =  100\n",
      "3 3\n",
      "[198.5431  198.44913 198.29292 198.55066 198.76324]\n",
      "198.76324 step =  101\n",
      "4 4\n",
      "[197.63771 197.42345 197.37625 197.55429 197.78543]\n",
      "197.78543 step =  102\n",
      "4 4\n",
      "[196.442   196.26324 196.50165 196.76529 196.80972]\n",
      "196.76529 step =  103\n",
      "3 3\n",
      "[195.70497 195.59097 195.5531  195.67049 195.83388]\n",
      "195.83388 step =  104\n",
      "4 4\n",
      "[194.72224 194.35846 194.4145  194.57986 194.7692 ]\n",
      "194.7692 step =  105\n",
      "4 4\n",
      "[193.44426 193.28438 193.53357 193.65492 193.71207]\n",
      "193.65492 step =  106\n",
      "3 3\n",
      "[192.56615 192.30557 192.26323 192.3441  192.56152]\n",
      "192.56615 step =  107\n",
      "4 0\n",
      "[192.11215 192.09712 192.16862 192.28018 192.43362]\n",
      "192.28018 step =  108\n",
      "3 3\n",
      "[191.47304 191.24625 191.28508 191.3368  191.4447 ]\n",
      "191.47304 step =  109\n",
      "4 0\n",
      "[191.15527 191.09691 191.23088 191.32204 191.32518]\n",
      "191.32518 step =  110\n",
      "4 4\n",
      "[190.15576 189.98448 190.08052 190.27596 190.40225]\n",
      "190.40225 step =  111\n",
      "4 4\n",
      "[189.17274 189.18242 189.46315 189.62358 189.67215]\n",
      "189.62358 step =  112\n",
      "3 3\n",
      "[188.65106 188.65097 188.90102 189.0747  189.06358]\n",
      "189.0747 step =  113\n",
      "4 3\n",
      "[188.03256 187.94492 188.0232  188.23181 188.40764]\n",
      "188.40764 step =  114\n",
      "4 4\n",
      "[187.14944 187.04337 187.11209 187.36813 187.57098]\n",
      "187.57098 step =  115\n",
      "4 4\n",
      "[186.27559 186.23167 186.52536 186.7121  186.74484]\n",
      "186.7121 step =  116\n",
      "3 3\n",
      "[185.53302 185.4758  185.58444 185.81706 186.03542]\n",
      "186.03542 step =  117\n",
      "4 4\n",
      "[184.66782 184.5274  184.67464 184.84142 185.08969]\n",
      "185.08969 step =  118\n",
      "4 4\n",
      "[183.5695  183.58075 183.62086 183.64691 183.97816]\n",
      "183.97816 step =  119\n",
      "4 4\n",
      "[183.02913 182.5519  182.53555 182.47739 182.45244]\n",
      "183.02913 step =  120\n",
      "4 0\n",
      "[183.06142 182.55779 182.54404 182.52847 182.58235]\n",
      "183.06142 step =  121\n",
      "4 0\n",
      "[183.11708 182.61801 182.57718 182.65852 182.80345]\n",
      "183.11708 step =  122\n",
      "4 0\n",
      "[182.89867 182.67354 182.76427 182.98514 183.21638]\n",
      "183.21638 step =  123\n",
      "4 4\n",
      "[181.94414 181.8417  182.09601 182.35988 182.33414]\n",
      "182.35988 step =  124\n",
      "3 3\n",
      "[181.27953 181.09244 181.18472 181.36076 181.59868]\n",
      "181.59868 step =  125\n",
      "4 4\n",
      "[180.21104 180.00137 180.0193  180.34575 180.53806]\n",
      "180.53806 step =  126\n",
      "4 4\n",
      "[179.24487 179.01167 179.24933 179.43166 179.43791]\n",
      "179.43166 step =  127\n",
      "3 3\n",
      "[178.22552 178.02698 178.05563 178.25911 178.49855]\n",
      "178.49855 step =  128\n",
      "4 4\n",
      "[177.17238 177.00266 176.97473 177.18431 177.33371]\n",
      "177.33371 step =  129\n",
      "4 4\n",
      "[176.23877 176.12946 176.11731 176.33412 176.48898]\n",
      "176.48898 step =  130\n",
      "4 4\n",
      "[175.384   175.31914 175.33289 175.48526 175.67229]\n",
      "175.67229 step =  131\n",
      "4 4\n",
      "[174.32118 174.14034 174.20187 174.39615 174.59361]\n",
      "174.59361 step =  132\n",
      "4 4\n",
      "[173.36041 173.20265 173.25822 173.46391 173.67798]\n",
      "173.67798 step =  133\n",
      "4 4\n",
      "[172.34862 172.18663 172.42758 172.6446  172.75946]\n",
      "172.6446 step =  134\n",
      "3 3\n",
      "[171.43365 171.23866 171.2659  171.45154 171.64961]\n",
      "171.64961 step =  135\n",
      "4 4\n",
      "[170.42078 170.26285 170.22093 170.48827 170.6861 ]\n",
      "170.6861 step =  136\n",
      "4 4\n",
      "[169.35886 169.29413 169.50972 169.64722 169.70876]\n",
      "169.64722 step =  137\n",
      "3 3\n",
      "[168.57256 168.47046 168.47847 168.57962 168.76419]\n",
      "168.76419 step =  138\n",
      "4 4\n",
      "[167.51779 167.43852 167.48703 167.59052 167.78993]\n",
      "167.78993 step =  139\n",
      "4 4\n",
      "[166.48221 166.31703 166.58678 166.72028 166.83406]\n",
      "166.72028 step =  140\n",
      "3 3\n",
      "[165.82582 165.64313 165.68874 165.84438 166.0477 ]\n",
      "166.0477 step =  141\n",
      "4 4\n",
      "[164.74323 164.58789 164.64496 164.81812 165.02315]\n",
      "165.02315 step =  142\n",
      "4 4\n",
      "[163.8453  163.71991 163.95425 164.15436 164.24586]\n",
      "164.15436 step =  143\n",
      "3 3\n",
      "[163.17534 163.12158 163.13611 163.34438 163.5866 ]\n",
      "163.5866 step =  144\n",
      "4 4\n",
      "[162.28325 162.22072 162.29248 162.50482 162.67986]\n",
      "162.67986 step =  145\n",
      "4 4\n",
      "[161.41216 161.30081 161.29947 161.45569 161.70497]\n",
      "161.70497 step =  146\n",
      "4 4\n",
      "[160.79578 160.25807 160.25433 160.20604 160.16699]\n",
      "160.79578 step =  147\n",
      "4 0\n",
      "[160.66028 160.15128 160.14711 160.09096 160.09628]\n",
      "160.66028 step =  148\n",
      "4 0\n",
      "[160.63356 160.18274 160.16806 160.20055 160.38405]\n",
      "160.63356 step =  149\n",
      "4 0\n",
      "[160.40573 160.16753 160.21164 160.3787  160.62534]\n",
      "160.62534 step =  150\n",
      "4 4\n",
      "[159.36433 159.18079 159.39291 159.58864 159.62067]\n",
      "159.58864 step =  151\n",
      "3 3\n",
      "[158.5132  158.35313 158.35281 158.55484 158.78268]\n",
      "158.78268 step =  152\n",
      "4 4\n",
      "[157.5069  157.35292 157.36205 157.54878 157.78882]\n",
      "157.78882 step =  153\n",
      "4 4\n",
      "[156.61435 156.49286 156.68004 156.87428 156.8959 ]\n",
      "156.87428 step =  154\n",
      "3 3\n",
      "[155.82753 155.82382 155.87502 156.02782 156.25763]\n",
      "156.25763 step =  155\n",
      "4 4\n",
      "[154.96165 154.90271 154.86781 155.05894 155.31534]\n",
      "155.31534 step =  156\n",
      "4 4\n",
      "[154.23277 153.65552 153.73877 153.7096  153.75346]\n",
      "154.23277 step =  157\n",
      "4 0\n",
      "[154.233   153.61188 153.66187 153.61009 153.69559]\n",
      "154.233 step =  158\n",
      "4 0\n",
      "[154.247   153.63615 153.66273 153.61803 153.74446]\n",
      "154.247 step =  159\n",
      "4 0\n",
      "[154.15666 153.73141 153.77333 153.89787 154.13272]\n",
      "154.15666 step =  160\n",
      "4 0\n",
      "[153.92365 153.65936 153.71109 153.88698 154.1042 ]\n",
      "154.1042 step =  161\n",
      "4 4\n",
      "[153.00298 152.54707 152.61552 152.88179 152.95425]\n",
      "153.00298 step =  162\n",
      "1 0\n",
      "[152.79266 152.61537 152.65318 152.91203 153.07065]\n",
      "153.07065 step =  163\n",
      "4 4\n",
      "[151.64783 151.67291 151.90617 152.06401 152.08315]\n",
      "152.06401 step =  164\n",
      "3 3\n",
      "[150.99475 150.78514 150.98085 151.1383  151.18468]\n",
      "151.18468 step =  165\n",
      "4 4\n",
      "[149.84035 149.82811 149.91208 150.05293 150.24274]\n",
      "150.24274 step =  166\n",
      "4 4\n",
      "[148.98114 148.97081 149.2345  149.36198 149.45726]\n",
      "149.36198 step =  167\n",
      "3 3\n",
      "[148.4316  148.24934 148.46167 148.64778 148.67337]\n",
      "148.67337 step =  168\n",
      "4 4\n",
      "[147.38062 147.13441 147.24794 147.48022 147.6476 ]\n",
      "147.6476 step =  169\n",
      "4 4\n",
      "[146.408   146.25345 146.46428 146.69641 146.75696]\n",
      "146.69641 step =  170\n",
      "3 3\n",
      "[145.61722 145.39934 145.59735 145.83693 145.85254]\n",
      "145.85254 step =  171\n",
      "4 4\n",
      "[144.5122  144.43045 144.54568 144.69083 144.84671]\n",
      "144.84671 step =  172\n",
      "4 4\n",
      "[143.49539 143.4299  143.64474 143.8387  143.86586]\n",
      "143.8387 step =  173\n",
      "3 3\n",
      "[142.79834 142.58969 142.81273 142.99791 142.9961 ]\n",
      "142.99791 step =  174\n",
      "4 3\n",
      "[141.99045 141.81938 141.81555 142.00789 142.22351]\n",
      "142.22351 step =  175\n",
      "4 4\n",
      "[141.11758 140.87025 140.90828 141.10747 141.30136]\n",
      "141.30136 step =  176\n",
      "4 4\n",
      "[140.12927 140.00903 140.23201 140.44167 140.49884]\n",
      "140.44167 step =  177\n",
      "3 3\n",
      "[139.27942 139.11989 139.10672 139.29495 139.5054 ]\n",
      "139.5054 step =  178\n",
      "4 4\n",
      "[138.27    138.23933 138.13683 138.29243 138.46762]\n",
      "138.46762 step =  179\n",
      "4 4\n",
      "[137.30557 137.2107  137.2278  137.45032 137.63966]\n",
      "137.63966 step =  180\n",
      "4 4\n",
      "[136.25253 136.14813 136.16412 136.41191 136.59326]\n",
      "136.59326 step =  181\n",
      "4 4\n",
      "[135.27579 135.1699  135.24347 135.46164 135.63092]\n",
      "135.63092 step =  182\n",
      "4 4\n",
      "[134.27098 134.29527 134.35257 134.63504 134.77594]\n",
      "134.77594 step =  183\n",
      "4 4\n",
      "[133.3169  133.17513 133.45213 133.72945 133.7367 ]\n",
      "133.72945 step =  184\n",
      "3 3\n",
      "[132.57716 132.4391  132.43707 132.60995 132.80597]\n",
      "132.80597 step =  185\n",
      "4 4\n",
      "[131.68265 131.46075 131.47052 131.64206 131.81696]\n",
      "131.81696 step =  186\n",
      "4 4\n",
      "[130.64145 130.48624 130.664   130.81345 130.85632]\n",
      "130.81345 step =  187\n",
      "3 3\n",
      "[129.77966 129.65892 129.64627 129.78131 129.98895]\n",
      "129.98895 step =  188\n",
      "4 4\n",
      "[128.78928 128.57655 128.63588 128.77061 128.97482]\n",
      "128.97482 step =  189\n",
      "4 4\n",
      "[127.728455 127.51796  127.74079  127.88351  127.9133  ]\n",
      "127.88351 step =  190\n",
      "3 3\n",
      "[126.946594 126.813515 126.80512  126.96335  127.13844 ]\n",
      "127.13844 step =  191\n",
      "4 4\n",
      "[125.86618  125.773155 125.761696 125.91388  126.11549 ]\n",
      "126.11549 step =  192\n",
      "4 4\n",
      "[124.91886  124.733185 124.969986 125.15971  125.180115]\n",
      "125.15971 step =  193\n",
      "3 3\n",
      "[124.124596 124.02307  124.032196 124.20557  124.44995 ]\n",
      "124.44995 step =  194\n",
      "4 4\n",
      "[123.05597  122.955185 123.00093  123.188446 123.424545]\n",
      "123.424545 step =  195\n",
      "4 4\n",
      "[122.04126  121.92775  121.921844 122.10448  122.3553  ]\n",
      "122.3553 step =  196\n",
      "4 4\n",
      "[121.44542  120.909065 120.904335 120.83854  120.81899 ]\n",
      "121.44542 step =  197\n",
      "4 0\n",
      "[121.50579  120.95393  120.969086 120.933235 120.977776]\n",
      "121.50579 step =  198\n",
      "4 0\n",
      "[121.51891  121.03317  120.96981  121.028114 121.19252 ]\n",
      "121.51891 step =  199\n",
      "4 0\n",
      "[121.340324 121.10341  121.09646  121.29404  121.546585]\n",
      "121.546585 step =  200\n",
      "4 4\n",
      "[120.21147  120.05826  120.28587  120.46489  120.497345]\n",
      "120.46489 step =  201\n",
      "3 3\n",
      "[119.5157   119.336784 119.302505 119.47296  119.7201  ]\n",
      "119.7201 step =  202\n",
      "4 4\n",
      "[118.35098 118.19131 118.21972 118.38904 118.59049]\n",
      "118.59049 step =  203\n",
      "4 4\n",
      "[117.3736  117.15788 117.41072 117.60889 117.66504]\n",
      "117.60889 step =  204\n",
      "3 3\n",
      "[116.63299  116.50487  116.451225 116.68248  116.973175]\n",
      "116.973175 step =  205\n",
      "4 4\n",
      "[115.71383  115.58378  115.56478  115.81818  116.061745]\n",
      "116.061745 step =  206\n",
      "4 4\n",
      "[114.82797  114.67127  114.60268  114.84456  115.122536]\n",
      "115.122536 step =  207\n",
      "4 4\n",
      "[114.12636 113.52893 113.53666 113.49297 113.4968 ]\n",
      "114.12636 step =  208\n",
      "4 0\n",
      "[114.0083   113.438255 113.45738  113.38417  113.42502 ]\n",
      "114.0083 step =  209\n",
      "4 0\n",
      "[113.943054 113.479774 113.44977  113.45653  113.692924]\n",
      "113.943054 step =  210\n",
      "4 0\n",
      "[113.73461  113.480934 113.52408  113.68954  113.96854 ]\n",
      "113.96854 step =  211\n",
      "4 4\n",
      "[112.73873 112.52432 112.75671 112.95845 113.00795]\n",
      "112.95845 step =  212\n",
      "3 3\n",
      "[111.907555 111.721016 111.719894 111.93744  112.15834 ]\n",
      "112.15834 step =  213\n",
      "4 4\n",
      "[110.91218  110.718925 110.74298  110.940155 111.14704 ]\n",
      "111.14704 step =  214\n",
      "4 4\n",
      "[109.95596  109.77173  109.997086 110.22623  110.23006 ]\n",
      "110.22623 step =  215\n",
      "3 3\n",
      "[109.1584   109.051704 109.10443  109.339516 109.61289 ]\n",
      "109.61289 step =  216\n",
      "4 4\n",
      "[108.39142  108.17573  108.129105 108.387596 108.678055]\n",
      "108.678055 step =  217\n",
      "4 4\n",
      "[107.62183  107.09238  107.11575  107.130745 107.15366 ]\n",
      "107.62183 step =  218\n",
      "4 0\n",
      "[107.64559  107.03917  107.03246  107.01325  107.080215]\n",
      "107.64559 step =  219\n",
      "4 0\n",
      "[107.66067 107.06962 107.0385  107.04189 107.16483]\n",
      "107.66067 step =  220\n",
      "4 0\n",
      "[107.6068  107.16024 107.10268 107.29286 107.53886]\n",
      "107.6068 step =  221\n",
      "4 0\n",
      "[107.40854  107.10075  107.113785 107.33519  107.543594]\n",
      "107.543594 step =  222\n",
      "4 4\n",
      "[106.453255 106.16261  106.05398  106.26426  106.41479 ]\n",
      "106.453255 step =  223\n",
      "1 0\n",
      "[106.313324 106.25535  106.16435  106.33791  106.504166]\n",
      "106.504166 step =  224\n",
      "4 4\n",
      "[105.32591 105.2641  105.4355  105.59658 105.61214]\n",
      "105.59658 step =  225\n",
      "3 3\n",
      "[104.59284 104.42455 104.63219 104.81245 104.84022]\n",
      "104.84022 step =  226\n",
      "4 4\n",
      "[103.489296 103.394745 103.39067  103.627464 103.833855]\n",
      "103.833855 step =  227\n",
      "4 4\n",
      "[102.559364 102.51492  102.638916 102.87316  102.94471 ]\n",
      "102.87316 step =  228\n",
      "3 3\n",
      "[101.86918  101.54936  101.75004  101.997955 102.009415]\n",
      "102.009415 step =  229\n",
      "4 4\n",
      "[100.61469 100.47089 100.41153 100.6569  100.84041]\n",
      "100.84041 step =  230\n",
      "4 4\n",
      "[99.65602  99.53129  99.66933  99.88857  99.961754]\n",
      "99.88857 step =  231\n",
      "3 3\n",
      "[98.9453  98.77492 98.98142 99.16227 99.16101]\n",
      "99.16227 step =  232\n",
      "4 3\n",
      "[98.183395 98.06971  98.02391  98.27483  98.50645 ]\n",
      "98.50645 step =  233\n",
      "4 4\n",
      "[97.27636 97.09439 97.098   97.30934 97.52408]\n",
      "97.52408 step =  234\n",
      "4 4\n",
      "[96.235756 95.977005 96.2445   96.45964  96.47304 ]\n",
      "96.45964 step =  235\n",
      "3 3\n",
      "[95.395996 95.18812  95.19695  95.39253  95.597435]\n",
      "95.597435 step =  236\n",
      "4 4\n",
      "[94.37414  94.11615  94.161026 94.35276  94.55097 ]\n",
      "94.55097 step =  237\n",
      "4 4\n",
      "[93.36147 93.15036 93.41922 93.63425 93.6326 ]\n",
      "93.63425 step =  238\n",
      "3 3\n",
      "[92.669914 92.45313  92.52304  92.73006  92.95962 ]\n",
      "92.95962 step =  239\n",
      "4 4\n",
      "[91.69754  91.613495 91.645905 91.78573  92.01731 ]\n",
      "92.01731 step =  240\n",
      "4 4\n",
      "[90.734634 90.61127  90.59177  90.6131   90.97551 ]\n",
      "90.97551 step =  241\n",
      "4 4\n",
      "[90.104004 89.66777  89.63387  89.61228  89.60367 ]\n",
      "90.104004 step =  242\n",
      "4 0\n",
      "[90.201225 89.65667  89.6746   89.66456  89.716385]\n",
      "90.201225 step =  243\n",
      "4 0\n",
      "[90.24362 89.704   89.68184 89.74866 89.89574]\n",
      "90.24362 step =  244\n",
      "4 0\n",
      "[90.04618  89.675026 89.71572  89.92504  90.14728 ]\n",
      "90.14728 step =  245\n",
      "4 4\n",
      "[89.03624  88.79395  89.019455 89.24892  89.2562  ]\n",
      "89.24892 step =  246\n",
      "3 3\n",
      "[88.21465  88.032616 88.068375 88.22415  88.45767 ]\n",
      "88.45767 step =  247\n",
      "4 4\n",
      "[87.139626 86.830154 86.87914  87.095604 87.321724]\n",
      "87.321724 step =  248\n",
      "4 4\n",
      "[86.08045  85.79637  86.02757  86.23491  86.272125]\n",
      "86.23491 step =  249\n",
      "3 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 2\n",
      "[6.1001635 5.752891  5.7889385 6.0381613 6.3341684]\n",
      "6.3341684 step =  350\n",
      "4 4\n",
      "[5.0388155 5.0385437 5.3098497 5.237028  5.3443546]\n",
      "5.3443546 step =  351\n",
      "4 4\n",
      "[3.9960783 3.923573  4.2567863 4.2435217 4.2822614]\n",
      "4.2567863 step =  352\n",
      "2 2\n",
      "[3.5008194 3.0657706 3.1380017 3.426208  3.7250795]\n",
      "3.7250795 step =  353\n",
      "4 4\n",
      "[2.7462485 2.268437  2.3792748 2.3860312 2.3403435]\n",
      "2.7462485 step =  354\n",
      "4 0\n",
      "[2.7447503 2.2793999 2.349829  2.31647   2.268027 ]\n",
      "2.7447503 step =  355\n",
      "4 0\n",
      "[2.7302375 2.1647072 2.04552   2.1063867 2.2158291]\n",
      "2.7302375 step =  356\n",
      "4 0\n",
      "[2.7348595 2.1548603 2.096592  2.2440133 2.3644643]\n",
      "2.7348595 step =  357\n",
      "4 0\n",
      "[2.5822659 2.2099311 2.2969174 2.5049095 2.7217467]\n",
      "2.7217467 step =  358\n",
      "4 4\n",
      "[1.5232882 1.3702471 1.5293615 1.7417244 1.7217208]\n",
      "1.7417244 step =  359\n",
      "3 3\n",
      "[0.73691326 0.5673262  0.57287824 0.74788356 1.0189244 ]\n",
      "1.0189244 step =  360\n",
      "4 4\n",
      "1101\n"
     ]
    }
   ],
   "source": [
    "model = agent.model\n",
    "#model.load_weights('D:/WFH2020/210202_IOC/RL/TrainingModel/Model_V4_0_Large')\n",
    "#model.set_weights(agent.target_model.get_weights())\n",
    "env.reset()\n",
    "#print (env.max_opt)\n",
    "#model = agent.model\n",
    "step = 0\n",
    "count = 0\n",
    "while not env.done:\n",
    "    state = env.map\n",
    "    q_table = model.predict(np.array(state).reshape(-1, *state.shape)/4)[0]\n",
    "    a = env.max_opt\n",
    "    action = np.argmax(q_table[:env.max_opt+1])\n",
    "    print (q_table)\n",
    "    print (np.max(q_table[:env.max_opt+1]), \"step = \", step)\n",
    "    \n",
    "    print (a,action)\n",
    "    env.move(action)\n",
    "    step += 1\n",
    "    \n",
    "    #print (\"count = \",count)\n",
    "#plt.imshow(env.map.reshape(12,13)/4,cmap=plt.cm.binary)\n",
    "#plt.show()\n",
    "print (env.count_total)\n",
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (agent.replay_memory[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xpoints = np.array(plotting[0])\n",
    "ypoints = np.array(plotting[1])\n",
    "print (np.max(plotting[1]))\n",
    "xpoints = np.mean(xpoints.reshape(-1, 5), axis=1)\n",
    "ypoints = np.mean(ypoints.reshape(-1, 5), axis=1)\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.savefig('X:/henan.liu/__ML/Plot/Model_V4_1_2457_B_5.pdf')\n",
    "plt.show()\n",
    "print (np.argmax(ypoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
